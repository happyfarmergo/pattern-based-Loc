{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utm\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "\n",
    "import load, plot\n",
    "import tools\n",
    "import pygrid\n",
    "import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'jiading'\n",
    "datatype = '2g'\n",
    "data_file = './data/%s_%s/data_%s.csv' % (dataset, datatype, datatype)\n",
    "gongcan_file = './data/%s_%s/gongcan_%s.csv' % (dataset, datatype, datatype)\n",
    "disp_path = './display/%s_%s/' % (dataset, datatype)\n",
    "data_path = './data/%s_%s/' % (dataset, datatype)\n",
    "map_file = './data/%s_map/%s_EdgeGeometry.txt' % (dataset, dataset)\n",
    "edge_file = './data/%s_map/%s_Edges.txt' % (dataset, dataset)\n",
    "node_file = './data/%s_map/%s_Nodes.txt' % (dataset, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traj ID=0\n",
      "0->1:286m\t\n",
      "discard[0:0]=0m\tkeep[1:24]as id=0\t\n",
      "[24]\n",
      "Traj ID=1\n",
      "32->33:510m\t\n",
      "discard[25:32]=0m\tkeep[33:182]as id=1\t\n",
      "[150]\n",
      "Traj ID=2\n",
      "\n",
      "keep[183:216]as id=2\t\n",
      "[34]\n",
      "Traj ID=3\n",
      "217->218:394m\t\n",
      "discard[217:217]=0m\tkeep[218:261]as id=3\t\n",
      "[44]\n",
      "Traj ID=4\n",
      "263->264:118m\t\n",
      "discard[262:263]=0m\tkeep[264:311]as id=4\t\n",
      "[48]\n",
      "Traj ID=5\n",
      "313->314:522m\t424->425:752m\t445->446:116m\t\n",
      "discard[312:313]=0m\ttrimed[0,89] keep[314:335]as id=5\tdiscard[425:445]=33m\tdiscard[446:447]=0m\t\n",
      "[22]\n",
      "Traj ID=6\n",
      "457->458:101m\t\n",
      "discard[448:457]=0m\tkeep[458:560]as id=6\t\n",
      "[103]\n",
      "Traj ID=7\n",
      "\n",
      "keep[561:934]as id=7\t\n",
      "[374]\n",
      "Traj ID=8\n",
      "936->937:947m\t\n",
      "discard[935:936]=0m\tkeep[937:1276]as id=8\t\n",
      "[340]\n",
      "Traj ID=9\n",
      "\n",
      "keep[1277:1697]as id=9\t\n",
      "[421]\n",
      "Traj ID=10\n",
      "\n",
      "keep[1698:1993]as id=10\t\n",
      "[296]\n",
      "Traj ID=11\n",
      "\n",
      "keep[1994:2416]as id=11\t\n",
      "[423]\n",
      "Traj ID=12\n",
      "2452->2453:838m\t\n",
      "discard[2417:2452]=0m\tkeep[2453:3432]as id=12\t\n",
      "[980]\n",
      "Traj ID=13\n",
      "\n",
      "keep[3433:4259]as id=13\t\n",
      "[827]\n",
      "Traj ID=14\n",
      "4302->4303:667m\t\n",
      "keep[4260:4302]as id=14\tkeep[4303:4374]as id=15\t\n",
      "[43, 72]\n",
      "Traj ID=15\n",
      "4377->4378:482m\t4720->4721:714m\t\n",
      "discard[4375:4377]=0m\tkeep[4378:4720]as id=16\tkeep[4721:5228]as id=17\t\n",
      "[343, 508]\n",
      "Traj ID=16\n",
      "\n",
      "trimed[1,12] keep[5230:5463]as id=18\t\n",
      "[234]\n",
      "Traj ID=17\n",
      "5479->5480:150m\t\n",
      "discard[5476:5479]=0m\ttrimed[5,92] keep[5485:5731]as id=19\t\n",
      "[247]\n",
      "Traj ID=18\n",
      "5922->5923:468m\t\n",
      "discard[5824:5922]=0m\tkeep[5923:6150]as id=20\t\n",
      "[228]\n",
      "Traj ID=19\n",
      "\n",
      "keep[6151:6340]as id=21\t\n",
      "[190]\n",
      "Traj ID=20\n",
      "6381->6382:104m\t\n",
      "discard[6341:6381]=58m\tkeep[6382:6597]as id=22\t\n",
      "[216]\n",
      "Traj ID=21\n",
      "6606->6607:569m\t\n",
      "discard[6598:6606]=0m\tkeep[6607:6787]as id=23\t\n",
      "[181]\n",
      "Traj ID=22\n",
      "\n",
      "keep[6788:7214]as id=24\t\n",
      "[427]\n",
      "Traj ID=23\n",
      "7218->7219:1075m\t\n",
      "discard[7215:7218]=0m\tkeep[7219:7403]as id=25\t\n",
      "[185]\n",
      "Traj ID=24\n",
      "7409->7410:479m\t\n",
      "discard[7404:7409]=0m\ttrimed[7,28] keep[7417:7675]as id=26\t\n",
      "[259]\n",
      "Traj ID=25\n",
      "7742->7743:917m\t\n",
      "discard[7704:7742]=0m\tkeep[7743:8122]as id=27\t\n",
      "[380]\n",
      "Traj ID=26\n",
      "8154->8155:180m\t\n",
      "discard[8123:8154]=0m\ttrimed[1,11] keep[8156:8641]as id=28\t\n",
      "[486]\n",
      "Traj ID=27\n",
      "\n",
      "keep[8653:8737]as id=29\t\n",
      "[85]\n",
      "Traj ID=28\n",
      "\n",
      "keep[8738:8826]as id=30\t\n",
      "[89]\n",
      "Traj ID=29\n",
      "\n",
      "keep[8827:8887]as id=31\t\n",
      "[61]\n",
      "Traj ID=30\n",
      "\n",
      "keep[8888:9033]as id=32\t\n",
      "[146]\n",
      "Traj ID=31\n",
      "\n",
      "keep[9034:9273]as id=33\t\n",
      "[240]\n",
      "Traj ID=32\n",
      "\n",
      "keep[9274:9353]as id=34\t\n",
      "[80]\n",
      "Traj ID=33\n",
      "\n",
      "keep[9354:9462]as id=35\t\n",
      "[109]\n",
      "Traj ID=34\n",
      "\n",
      "keep[9463:9582]as id=36\t\n",
      "[120]\n",
      "Traj ID=35\n",
      "\n",
      "keep[9583:9672]as id=37\t\n",
      "[90]\n",
      "Traj ID=36\n",
      "\n",
      "keep[9673:9786]as id=38\t\n",
      "[114]\n",
      "Traj ID=37\n",
      "\n",
      "keep[9787:9874]as id=39\t\n",
      "[88]\n",
      "Traj ID=38\n",
      "\n",
      "keep[9875:10055]as id=40\t\n",
      "[181]\n",
      "Traj ID=39\n",
      "\n",
      "keep[10056:10109]as id=41\t\n",
      "[54]\n",
      "Traj ID=40\n",
      "\n",
      "keep[10110:10207]as id=42\t\n",
      "[98]\n",
      "Traj ID=41\n",
      "\n",
      "keep[10208:10343]as id=43\t\n",
      "[136]\n",
      "Traj ID=42\n",
      "\n",
      "keep[10344:10419]as id=44\t\n",
      "[76]\n",
      "Traj ID=43\n",
      "\n",
      "keep[10420:10473]as id=45\t\n",
      "[54]\n",
      "Traj ID=44\n",
      "\n",
      "keep[10474:10549]as id=46\t\n",
      "[76]\n",
      "Traj ID=45\n",
      "\n",
      "keep[10550:10625]as id=47\t\n",
      "[76]\n",
      "Traj ID=46\n",
      "10627->10628:605m\t\n",
      "discard[10626:10627]=0m\tkeep[10628:10679]as id=48\t\n",
      "[52]\n",
      "Traj ID=47\n",
      "\n",
      "trimed[4,16] keep[10684:10902]as id=49\t\n",
      "[219]\n",
      "Traj ID=48\n",
      "\n",
      "keep[10919:11240]as id=50\t\n",
      "[322]\n",
      "Traj ID=49\n",
      "11243->11244:125m\t\n",
      "discard[11241:11243]=0m\tkeep[11244:11353]as id=51\t\n",
      "[110]\n",
      "Traj ID=50\n",
      "11354->11355:281m\t\n",
      "discard[11354:11354]=0m\tkeep[11355:11429]as id=52\t\n",
      "[75]\n",
      "Traj ID=51\n",
      "\n",
      "keep[11430:11481]as id=53\t\n",
      "[52]\n",
      "Traj ID=52\n",
      "11483->11484:157m\t\n",
      "discard[11482:11483]=0m\tkeep[11484:11556]as id=54\t\n",
      "[73]\n",
      "Traj ID=53\n",
      "\n",
      "keep[11557:11611]as id=55\t\n",
      "[55]\n",
      "Traj ID=54\n",
      "\n",
      "keep[11612:11662]as id=56\t\n",
      "[51]\n",
      "Traj ID=55\n",
      "\n",
      "keep[11663:11720]as id=57\t\n",
      "[58]\n",
      "Traj ID=56\n",
      "11722->11723:121m\t\n",
      "discard[11721:11722]=0m\tkeep[11723:11769]as id=58\t\n",
      "[47]\n",
      "Traj ID=57\n",
      "\n",
      "keep[11770:11876]as id=59\t\n",
      "[107]\n",
      "Traj ID=58\n",
      "11877->11878:274m\t\n",
      "discard[11877:11877]=0m\tkeep[11878:11962]as id=60\t\n",
      "[85]\n",
      "Traj ID=59\n",
      "11974->11975:143m\t\n",
      "discard[11963:11974]=0m\tkeep[11975:12022]as id=61\t\n",
      "[48]\n",
      "Traj ID=60\n",
      "\n",
      "keep[12023:12107]as id=62\t\n",
      "[85]\n",
      "Traj ID=61\n",
      "\n",
      "keep[12108:12592]as id=63\t\n",
      "[485]\n",
      "Traj ID=62\n",
      "\n",
      "keep[12593:12654]as id=64\t\n",
      "[62]\n",
      "Traj ID=63\n",
      "\n",
      "keep[12655:12743]as id=65\t\n",
      "[89]\n",
      "Traj ID=64\n",
      "\n",
      "keep[12744:12833]as id=66\t\n",
      "[90]\n",
      "Traj ID=65\n",
      "\n",
      "keep[12834:12914]as id=67\t\n",
      "[81]\n",
      "Traj ID=66\n",
      "12934->12935:108m\t\n",
      "discard[12915:12934]=0m\tkeep[12935:12979]as id=68\t\n",
      "[45]\n",
      "Traj ID=67\n",
      "\n",
      "trimed[2,15] keep[12982:13049]as id=69\t\n",
      "[68]\n",
      "Traj ID=68\n",
      "\n",
      "keep[13065:13114]as id=70\t\n",
      "[50]\n",
      "Traj ID=69\n",
      "13140->13141:353m\t\n",
      "discard[13115:13140]=0m\tkeep[13141:13190]as id=71\t\n",
      "[50]\n"
     ]
    }
   ],
   "source": [
    "load = reload(load)\n",
    "tools = reload(tools)\n",
    "df_raw = load.load_data(data_file, gongcan_file)\n",
    "max_dist, min_dist, min_len, max_again = load.get_config(dataset, datatype)\n",
    "df = load.clean_data(df_raw, max_dist, min_dist, min_len, max_again, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(data_path + 'data_%s_clean.csv' % datatype, index=False)\n",
    "df = pd.read_csv(data_path + 'data_%s_clean.csv' % datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13191 12517\n"
     ]
    }
   ],
   "source": [
    "print (len(df_raw), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = reload(load)\n",
    "load.to_trajs(df, data_path + 'trajs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = reload(display)\n",
    "max_trid = max(df['TrajID'])\n",
    "for tr_id in range(max_trid + 1):\n",
    "    df_i = df[df['TrajID']==tr_id]\n",
    "    display.df_to_html(df_i, disp_path + 'path/%d.html' % tr_id, ('Latitude', 'Longitude'), more_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load = reload(load)\n",
    "useful_col = ['TrajID', 'MRTime', 'RoadID', 'Match_Lat', 'Match_Lng', 'Match_loc', 'Match_Dist']\n",
    "match_df = load.load_matching(data_path + 'matching_out', max(df['TrajID']), 50)[useful_col]\n",
    "len(match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12388"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, match_df, on=['TrajID', 'MRTime'])\n",
    "df = load.fill_utm_axis(df, ['Match_Lat', 'Match_Lng'], ['Match_UTM_X', 'Match_UTM_Y'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trid = max(df['TrajID'])\n",
    "for tr_id in range(max_trid + 1):\n",
    "    df_i = df[df['TrajID']==tr_id]\n",
    "    display.df_to_html(df_i, disp_path + 'match/%d.html' % tr_id, ('Match_Lat', 'Match_Lng'), more_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 550 210\n"
     ]
    }
   ],
   "source": [
    "load = reload(load)\n",
    "roadmap, edgemap, nodemap = load.load_map(map_file, edge_file, node_file, dataset)\n",
    "print (len(roadmap), len(edgemap), len(nodemap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = reload(display)\n",
    "display.map_to_html(roadmap, './display/%s_map.html' % dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygrid = reload(pygrid)\n",
    "if dataset == 'jiading':\n",
    "    bounding_box = (328500, 330600, 3462100, 3463600)\n",
    "elif dataset == 'siping':\n",
    "    bounding_box = (356000, 359000, 3461500, 3463000)\n",
    "side = 20\n",
    "grid = pygrid.Grid(side, bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11601 11601\n",
      "[(329964.3817175407, 3463039.681154026), (329960.64643888554, 3463039.2014535726), (329961.7555243264, 3463039.343893213), (329964.11835392227, 3463039.647331306), (329963.26938791166, 3463039.5383009496)]\n"
     ]
    }
   ],
   "source": [
    "process = reload(process)\n",
    "load = reload(load)\n",
    "towers, r_towers = load.load_gongcan(gongcan_file)\n",
    "w_size = 5\n",
    "cellids, patterns, statistic = process.retrive(df, grid, towers, edgemap, nodemap, w_size)\n",
    "print (len(cellids), len(patterns))\n",
    "print (patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin Labels: 10825\n",
      "Merged labels: 28\n"
     ]
    }
   ],
   "source": [
    "process = reload(process)\n",
    "labels, label_set, discard_idxs, len_stat = process.pattern2label(patterns, grid, version=2)\n",
    "features = process.cellids2feature(cellids, r_towers, discard_idxs, version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -79,\n",
       " 88,\n",
       " 31.291315,\n",
       " 121.217252,\n",
       " -83,\n",
       " 53,\n",
       " 31.287758,\n",
       " 121.22313100000001,\n",
       " -83,\n",
       " 79,\n",
       " 31.286457000000002,\n",
       " 121.215515,\n",
       " -81,\n",
       " 85,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -91,\n",
       " 84,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -87,\n",
       " 81,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -77,\n",
       " 81,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -75,\n",
       " 88,\n",
       " 31.291315,\n",
       " 121.217252,\n",
       " -81,\n",
       " 53,\n",
       " 31.287758,\n",
       " 121.22313100000001,\n",
       " -83,\n",
       " 79,\n",
       " 31.286457000000002,\n",
       " 121.215515,\n",
       " -83,\n",
       " 85,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -91,\n",
       " 84,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -87,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 81,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -75,\n",
       " 88,\n",
       " 31.291315,\n",
       " 121.217252,\n",
       " -81,\n",
       " 53,\n",
       " 31.287758,\n",
       " 121.22313100000001,\n",
       " -83,\n",
       " 79,\n",
       " 31.286457000000002,\n",
       " 121.215515,\n",
       " -83,\n",
       " 85,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -91,\n",
       " 84,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -87,\n",
       " 80,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -79,\n",
       " 81,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -73,\n",
       " 88,\n",
       " 31.291315,\n",
       " 121.217252,\n",
       " -83,\n",
       " 53,\n",
       " 31.287758,\n",
       " 121.22313100000001,\n",
       " -81,\n",
       " 79,\n",
       " 31.286457000000002,\n",
       " 121.215515,\n",
       " -81,\n",
       " 85,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -91,\n",
       " 84,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -85,\n",
       " 80,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -79,\n",
       " 81,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -73,\n",
       " 88,\n",
       " 31.291315,\n",
       " 121.217252,\n",
       " -83,\n",
       " 53,\n",
       " 31.287758,\n",
       " 121.22313100000001,\n",
       " -81,\n",
       " 79,\n",
       " 31.286457000000002,\n",
       " 121.215515,\n",
       " -81,\n",
       " 85,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -89,\n",
       " 84,\n",
       " 31.28055,\n",
       " 121.213089,\n",
       " -83,\n",
       " 80,\n",
       " 31.285957,\n",
       " 121.21734099999999,\n",
       " -79]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09818181818181818"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in len_stat if t > 60]) / len(len_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) : 1647 0.152\n",
      "(3,) : 2555 0.236\n",
      "(1,) : 2070 0.191\n",
      "(5,) : 1933 0.179\n",
      "(1, 3) : 183 0.017\n",
      "(7, 5) : 160 0.015\n",
      "(7,) : 1591 0.147\n",
      "(7, 1) : 104 0.010\n",
      "(7, 1, 7) : 9 0.001\n",
      "(1, 7) : 112 0.010\n",
      "(7, 5, 7) : 10 0.001\n",
      "(5, 7) : 136 0.013\n",
      "(3, 1) : 115 0.011\n",
      "(3, 1, 3) : 7 0.001\n",
      "(1, 7, 1) : 4 0.000\n",
      "(5, 3) : 68 0.006\n",
      "(5, 7, 5) : 5 0.000\n",
      "(5, 3, 5) : 6 0.001\n",
      "(5, 3, 5, 3) : 1 0.000\n",
      "(3, 5, 3) : 12 0.001\n",
      "(5, 7, 5, 3) : 1 0.000\n",
      "(3, 5) : 80 0.007\n",
      "(7, 1, 3) : 2 0.000\n",
      "(5, 7, 1) : 8 0.001\n",
      "(7, 5, 3) : 1 0.000\n",
      "(5, 3, 1) : 1 0.000\n",
      "(1, 3, 1) : 2 0.000\n",
      "(3, 5, 7) : 2 0.000\n",
      "0.006558891454965358\n"
     ]
    }
   ],
   "source": [
    "summary = dict()\n",
    "for label in labels:\n",
    "    pattern = label_set[label]\n",
    "    if pattern not in summary.keys():\n",
    "        summary[pattern] = 0\n",
    "    summary[pattern] += 1\n",
    "total = sum(cnt for cnt in summary.values())\n",
    "# print ((summary[(0,)] + summary[(1,)] + summary[(3,)] + summary[(5,)] + summary[(7,)]) / total)\n",
    "more2 = 0\n",
    "for pat, cnt in summary.items():\n",
    "    if len(pat) > 2:\n",
    "        more2 += cnt\n",
    "    print (pat, ':', cnt, '%.3f' % (cnt / 1.0 / total))\n",
    "print (more2 / 1.0 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = reload(plot)\n",
    "fig_width = 5\n",
    "axis = (-3, 3, -3, 3)\n",
    "for idx, pattern in enumerate(label_set):\n",
    "    plt.figure(figsize=(fig_width, fig_width*(axis[3]-axis[2])/(axis[1]-axis[0])))\n",
    "    ca = plt.gca()\n",
    "    plot.draw_pattern(pattern, ca, axis, 'k', debug=False)\n",
    "    plt.axis(axis)\n",
    "    plt.title('LabelID=' + str(idx))\n",
    "#     plt.show()\n",
    "    plt.savefig(disp_path + 'patterns/LabelID=%d.png' % idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328500, 330600, 3462100, 3463600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def round_axis(coors, bounding, ct):\n",
    "    x0, x1, y0, y1 = bounding\n",
    "    xs, ys = [coor[0] for coor in coors], [coor[1] for coor in coors]\n",
    "    mx, my = np.mean(xs), np.mean(ys)\n",
    "    x0_, x1_, y0_, y1_ = int(mx - ct), int(mx + ct), int(my - ct), int(my + ct)\n",
    "    return max(x0_, x0),  min(x1_, x1), max(y0_, y0), min(y1_, y1)\n",
    "\n",
    "plot = reload(plot)\n",
    "fig_width = 20\n",
    "cnt = 0\n",
    "for idx, pattern in enumerate(patterns):\n",
    "    if idx in discard_idxs:\n",
    "        continue\n",
    "    label_id = labels[cnt]\n",
    "    cnt += 1\n",
    "    if len(label_set[label_id]) < 3:\n",
    "        continue\n",
    "    axis = round_axis(pattern, bounding_box, 300)\n",
    "#     print (axis)\n",
    "    plt.figure(figsize=(fig_width, fig_width*(axis[3]-axis[2])/(axis[1]-axis[0])))\n",
    "    ca = plt.gca()\n",
    "    plot.draw_map(roadmap, ca, axis)\n",
    "    plot.draw_window_traj(pattern, ca, axis, 'k', debug=True)\n",
    "    plt.axis(axis)\n",
    "    plt.title('WindowID=%d_LabelID=%d'%(idx, label_id))\n",
    "#     plt.show()\n",
    "    plt.savefig(disp_path + 'pattern-traj/LabelID=%d_WindowID=%d.png' % (label_id, idx))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8118, 2707)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34096786110084965"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "# model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_predict = model.predict(X_test)\n",
    "tools = reload(tools)\n",
    "score = tools.accuracy(Y_test, Y_predict.round())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02979616, 0.03031118, 0.03343013, 0.03209802, 0.03319915,\n",
       "       0.03001348, 0.0165716 , 0.02850816, 0.02862437, 0.03472881,\n",
       "       0.03015807, 0.03055793, 0.02576935, 0.01490004, 0.02835399,\n",
       "       0.02704854, 0.03446568, 0.03023946, 0.0310846 , 0.02444784,\n",
       "       0.01376934, 0.02751484, 0.02952604, 0.03628921, 0.03146772,\n",
       "       0.03135697, 0.02654919, 0.01409116, 0.03042616, 0.03074543,\n",
       "       0.03582951, 0.0359151 , 0.0354411 , 0.03030579, 0.01646587])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_tr = X_train.reshape(-1, w_size, num_cellid, 1)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "X_te = X_test.reshape(-1, w_size, num_cellid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(label_set)\n",
    "num_cellid = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "Y_tr = to_categorical(pd.DataFrame(Y_train), num_classes=num_class)\n",
    "Y_te = to_categorical(pd.DataFrame(Y_test), num_classes=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_te[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5, 2)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cellid, w_size, num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 5, 7, 2), dtype=float32)\n",
      "Tensor(\"add_1:0\", shape=(?, 3, 4, 5), dtype=float32)\n",
      "Tensor(\"batchnorm/add_1:0\", shape=(?, 3, 4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Input Layer\n",
    "tf_X = tf.placeholder(tf.float32, [None, w_size, num_cellid, 1])\n",
    "tf_Y = tf.placeholder(tf.float32, [None, num_class])\n",
    "\n",
    "# Conv Layer\n",
    "# 卷积核太愚蠢\n",
    "conv_w1 = tf.Variable(tf.random_normal([w_size, num_cellid, 1, num_class]))\n",
    "conv_b1 = tf.Variable(tf.random_normal([num_class]))\n",
    "relu_feature_map1 = tf.nn.relu(tf.nn.conv2d(tf_X, conv_w1, strides=[1,1,1,1], padding='SAME') + conv_b1)\n",
    "print (relu_feature_map1)\n",
    "\n",
    "# Pooling Layer\n",
    "# max_pool1 = tf.nn.max_pool(relu_feature_map1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# Conv Layer 2\n",
    "conv_w2 = tf.Variable(tf.random_normal([w_size, num_cellid, num_class, 5]))\n",
    "conv_b2 = tf.Variable(tf.random_normal([5]))\n",
    "conv_out2 = tf.nn.conv2d(relu_feature_map1, conv_w2, strides=[1,2,2,1], padding='SAME') + conv_b2\n",
    "print (conv_out2)\n",
    "\n",
    "# Normalization\n",
    "batch_mean, batch_var = tf.nn.moments(conv_out2, [0, 1, 2], keep_dims=True)\n",
    "shift = tf.Variable(tf.zeros([5]))\n",
    "scale = tf.Variable(tf.ones([5]))\n",
    "epsilon = 1e-3\n",
    "BN_out = tf.nn.batch_normalization(conv_out2, batch_mean, batch_var, shift, scale, epsilon)\n",
    "print (BN_out)\n",
    "relu_BN_map2 = tf.nn.relu(BN_out)\n",
    "\n",
    "relu_BN_map2_flat = tf.reshape(relu_BN_map2, [-1, 3*4*5])\n",
    "\n",
    "#Fully Connection\n",
    "fc_w1 = tf.Variable(tf.random_normal([3*4*5, 64]))\n",
    "fc_b1 = tf.Variable(tf.random_normal([64]))\n",
    "fc_out1 = tf.nn.relu(tf.matmul(relu_BN_map2_flat, fc_w1) + fc_b1)\n",
    "\n",
    "# Output Layer\n",
    "out_w1 = tf.Variable(tf.random_normal([64, num_class]))\n",
    "out_b1 = tf.Variable(tf.random_normal([num_class]))\n",
    "pred = tf.nn.softmax(tf.matmul(fc_out1, out_w1) + out_b1)\n",
    "\n",
    "loss = -tf.reduce_mean(tf_Y*tf.log(tf.clip_by_value(pred, 1e-11, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "y_pred = tf.arg_max(pred, 1)\n",
    "bool_pred = tf.equal(tf.arg_max(tf_Y, 1), y_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 5, 7, 32), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 5, 7, 64), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 5, 7, 128), dtype=float32)\n",
      "Tensor(\"batchnorm/add_1:0\", shape=(?, 5, 7, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Input Layer\n",
    "tf_X = tf.placeholder(tf.float32, [None, w_size, num_cellid, 1])\n",
    "tf_Y = tf.placeholder(tf.float32, [None, num_class])\n",
    "\n",
    "# Conv Layer\n",
    "# 卷积核太愚蠢\n",
    "conv_w1 = tf.Variable(tf.random_normal([3, 3, 1, 32]))\n",
    "conv_b1 = tf.Variable(tf.random_normal([32]))\n",
    "conv_out1 = tf.nn.relu(tf.nn.conv2d(tf_X, conv_w1, strides=[1,1,1,1], padding='SAME') + conv_b1)\n",
    "print (conv_out1)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv_w2 = tf.Variable(tf.random_normal([3, 3, 32, 64]))\n",
    "conv_b2 = tf.Variable(tf.random_normal([64]))\n",
    "conv_out2 = tf.nn.relu(tf.nn.conv2d(conv_out1, conv_w2, strides=[1,1,1,1], padding='SAME') + conv_b2)\n",
    "print (conv_out2)\n",
    "\n",
    "# Conv Layer 3\n",
    "conv_w3 = tf.Variable(tf.random_normal([3, 3, 64, 128]))\n",
    "conv_b3 = tf.Variable(tf.random_normal([128]))\n",
    "conv_out3 = tf.nn.relu(tf.nn.conv2d(conv_out2, conv_w3, strides=[1,1,1,1], padding='SAME') + conv_b3)\n",
    "print (conv_out3)\n",
    "\n",
    "# Normalization\n",
    "batch_mean, batch_var = tf.nn.moments(conv_out3, [0, 1, 2], keep_dims=True)\n",
    "shift = tf.Variable(tf.zeros([128]))\n",
    "scale = tf.Variable(tf.ones([128]))\n",
    "epsilon = 1e-3\n",
    "BN_out = tf.nn.batch_normalization(conv_out3, batch_mean, batch_var, shift, scale, epsilon)\n",
    "print (BN_out)\n",
    "relu_BN_map2 = tf.nn.relu(BN_out)\n",
    "relu_BN_map2_flat = tf.reshape(relu_BN_map2, [-1, w_size * num_cellid * 128])\n",
    "\n",
    "#Fully Connection\n",
    "fc_w1 = tf.Variable(tf.random_normal([w_size * num_cellid * 128, 1000]))\n",
    "fc_b1 = tf.Variable(tf.random_normal([1000]))\n",
    "fc_out1 = tf.nn.relu(tf.matmul(relu_BN_map2_flat, fc_w1) + fc_b1)\n",
    "\n",
    "# Output Layer\n",
    "out_w1 = tf.Variable(tf.random_normal([1000, num_class]))\n",
    "out_b1 = tf.Variable(tf.random_normal([num_class]))\n",
    "pred = tf.nn.softmax(tf.matmul(fc_out1, out_w1) + out_b1)\n",
    "\n",
    "loss = -tf.reduce_mean(tf_Y*tf.log(tf.clip_by_value(pred, 1e-11, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "y_pred = tf.arg_max(pred, 1)\n",
    "bool_pred = tf.equal(tf.arg_max(tf_Y, 1), y_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0.5715, 0.786536\n",
      "50, 0.190565, 0.890129\n",
      "100, 0.180035, 0.893268\n",
      "150, 0.176448, 0.897454\n",
      "200, 0.172999, 0.896407\n",
      "250, 0.17235, 0.893268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-422-fc93ab1f3b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtf_X\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_Y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtf_X\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_Y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "def batch_get(X,Y,n_examples, batch_size):\n",
    "    for batch_i in range(n_examples // batch_size):\n",
    "        start = batch_i*batch_size\n",
    "        end = start + batch_size\n",
    "        batch_xs = X[start:end]\n",
    "        batch_ys = Y[start:end]\n",
    "        yield batch_xs, batch_ys # 生成每一个batch\n",
    "batch_size = 20\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(2000):\n",
    "        for batch_xs, batch_ys in batch_get(X_tr, Y_tr, Y_tr.shape[0], batch_size):\n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, tf_Y:batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            res = sess.run(accuracy, feed_dict={tf_X:X_tr, tf_Y:Y_tr})\n",
    "            lo=sess.run(loss,feed_dict={tf_X:X_tr,tf_Y:Y_tr})\n",
    "            test_res = sess.run(accuracy, feed_dict={tf_X:X_te, tf_Y:Y_te})\n",
    "            print ('%d, %g, %g' % (epoch, lo, test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
